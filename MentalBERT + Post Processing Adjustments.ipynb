{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a62e2f7",
   "metadata": {},
   "source": [
    "# Improved Model for Real World Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98d9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import ast\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3386be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"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\"  \n",
    "model_name = \"mental/mental-bert-base-uncased\"\n",
    "labels = [\"depression\", \"anxiety\", \"suicide\", \"casual\"]\n",
    "num_labels = len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa20c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"multi_label_mental_health_data.csv\")\n",
    "df[\"labels\"] = df[\"labels\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd26a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(l) == num_labels for l in df[\"labels\"]), \"Check label format!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804354b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"text\"], df[\"labels\"], test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e10e1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoya\\anaconda3\\envs\\mentalhealth\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962ec3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalHealthDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "train_dataset = MentalHealthDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = MentalHealthDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59cc03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoya\\anaconda3\\envs\\mentalhealth\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    token=hf_token,\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d860c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mentalbert-finetuned\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e196472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6223968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc6aa202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24750' max='24750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24750/24750 1:04:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.278644</td>\n",
       "      <td>0.805840</td>\n",
       "      <td>0.684512</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.298644</td>\n",
       "      <td>0.770962</td>\n",
       "      <td>0.737484</td>\n",
       "      <td>0.753770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.350728</td>\n",
       "      <td>0.764112</td>\n",
       "      <td>0.741963</td>\n",
       "      <td>0.751993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.459356</td>\n",
       "      <td>0.742961</td>\n",
       "      <td>0.732875</td>\n",
       "      <td>0.737362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.529795</td>\n",
       "      <td>0.741044</td>\n",
       "      <td>0.730763</td>\n",
       "      <td>0.735776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24750, training_loss=0.1847701290021039, metrics={'train_runtime': 3841.8374, 'train_samples_per_second': 51.534, 'train_steps_per_second': 6.442, 'total_flos': 1.302324443057664e+16, 'train_loss': 0.1847701290021039, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3677ca22",
   "metadata": {},
   "source": [
    "# Preparation for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0aee73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch textblob --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b1d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df5d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./mentalbert-finetuned\"  \n",
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368299c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1aac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Zoya/Downloads/mentalhealth_reddit_analysis.csv\")\n",
    "df[\"selftext\"] = df[\"selftext\"].fillna(\"\")\n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"selftext\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9846b46",
   "metadata": {},
   "source": [
    "Labels + Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd86f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"depression\", \"anxiety\", \"suicide\", \"casual\"]\n",
    "base_thresholds = {\"depression\": 0.2, \"anxiety\": 0.4, \"suicide\": 0.4, \"casual\": 0.15}\n",
    "anxiety_fallback_min = 0.07\n",
    "\n",
    "suicide_keywords = [\"end it\", \"disappear\", \"give up\", \"don't want to live\", \"kill myself\", \"take my life\"]\n",
    "casual_keywords = [\"walk\", \"sun\", \"weekend\", \"clear my head\", \"fresh air\", \"smiled\"]\n",
    "anxiety_phrases = [\"can't stop thinking\", \"heart keeps racing\", \"panic\", \"scared\", \"worry\", \"anxious\"]\n",
    "depression_phrases = [\"empty\", \"no motivation\", \"stuck in bed\", \"no point\", \"low moods\", \"nothing matters\", \"hopeless\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846846dc",
   "metadata": {},
   "source": [
    "Keyboard Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95c7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_boost(text, probs):\n",
    "    text = text.lower()\n",
    "    triggered = {\n",
    "        \"suicide\": any(kw in text for kw in suicide_keywords),\n",
    "        \"casual\": any(kw in text for kw in casual_keywords),\n",
    "        \"anxiety\": any(kw in text for kw in anxiety_phrases),\n",
    "        \"depression\": any(kw in text for kw in depression_phrases)\n",
    "    }\n",
    "    for label, active in triggered.items():\n",
    "        if active:\n",
    "            probs[labels.index(label)] += 0.1\n",
    "            probs[labels.index(label)] = min(1.0, probs[labels.index(label)])\n",
    "    return probs, triggered\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b844b7",
   "metadata": {},
   "source": [
    "Classification + Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f089383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_post(text):\n",
    "    sentiment = analyze_sentiment(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
    "    \n",
    "    if len(probs) != 4:\n",
    "        probs = [0.1] * 4\n",
    "\n",
    "    probs, triggered = keyword_boost(text, probs)\n",
    "    predicted_labels = []\n",
    "\n",
    "    for i, p in enumerate(probs):\n",
    "        label = labels[i]\n",
    "        if p >= base_thresholds[label]:\n",
    "            predicted_labels.append(label)\n",
    "\n",
    "    if \"suicide\" not in predicted_labels and triggered[\"suicide\"]:\n",
    "        if probs[labels.index(\"suicide\")] >= 0.2:\n",
    "            predicted_labels.append(\"suicide\")\n",
    "\n",
    "    if \"suicide\" in predicted_labels and probs[labels.index(\"depression\")] > 0.15:\n",
    "        if \"depression\" not in predicted_labels:\n",
    "            predicted_labels.append(\"depression\")\n",
    "\n",
    "    if sentiment > 0.2 and \"casual\" not in predicted_labels:\n",
    "        predicted_labels.append(\"casual\")\n",
    "\n",
    "    anxiety_score = probs[labels.index(\"anxiety\")]\n",
    "    if anxiety_score >= anxiety_fallback_min and \"anxiety\" not in predicted_labels:\n",
    "        if \"anxiety\" in text.lower() or triggered[\"anxiety\"]:\n",
    "            predicted_labels.append(\"anxiety\")\n",
    "\n",
    "    if len(predicted_labels) < 2:\n",
    "        top2 = probs.argsort()[-2:][::-1]\n",
    "        for i in top2:\n",
    "            if labels[i] not in predicted_labels:\n",
    "                predicted_labels.append(labels[i])\n",
    "\n",
    "    return predicted_labels, dict(zip(labels, [round(p, 3) for p in probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1abe6963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\zoya\\anaconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\zoya\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f9c6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts: 100%|██████████| 10000/10000 [02:37<00:00, 63.51post/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: mentalhealth_with_custom_labels.csv\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "label_results = []\n",
    "prob_results = []\n",
    "\n",
    "\n",
    "for text in tqdm(df[\"text\"], desc=\"Processing posts\", unit=\"post\"):\n",
    "    lbls, probs = process_post(text)\n",
    "    label_results.append(lbls)\n",
    "    prob_results.append(probs)\n",
    "\n",
    "df[\"predicted_labels\"] = label_results\n",
    "for label in labels:\n",
    "    df[label + \"_prob\"] = [probs[label] for probs in prob_results]\n",
    "\n",
    "\n",
    "df.to_csv(\"mentalhealth_with_custom_labels.csv\", index=False)\n",
    "print(\" Saved: mentalhealth_with_custom_labels.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mentalhealth)",
   "language": "python",
   "name": "mentalhealth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
